{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Implementasi Normalisasi\n",
    "def norm_data(data):\n",
    "    '''\n",
    "    Melakukan normalisasi data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list): Data yang akan dinormalisasi\n",
    "        \n",
    "    Returns:\n",
    "        data (list): Data hasil normalisasi    \n",
    "    '''\n",
    "    \n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_len = len(data)\n",
    "    \n",
    "    for i in range(0, data_len):\n",
    "        data[i] = (data[i] - data_min) / (data_max - data_min)\n",
    "        \n",
    "    return data\n",
    "\n",
    "# Contoh Penggunaan\n",
    "data = [10, 11, 12, 14, 16]\n",
    "n_data = norm_data(data) #melakukan normalisasi\n",
    "print(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[[100.       0.0001]\n",
      " [ 50.       0.05  ]\n",
      " [ 30.       0.003 ]]\n",
      "Data Normalisasi\n",
      "[[1.       0.      ]\n",
      " [0.285714 1.      ]\n",
      " [0.       0.058116]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.set_printoptions(precision=6) #bulatkan 4 angka koma\n",
    "np.set_printoptions(suppress=True) #hilangkan nilai e\n",
    "\n",
    "# Kita akan membentuk data\n",
    "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
    "# dalam bentuk n-dimensional array\n",
    "data = [\n",
    "    [100, 0.0001],\n",
    "    [50, 0.05],\n",
    "    [30, 0.003]\n",
    "]\n",
    "\n",
    "#Ubah ke bentuk numpy n-dimensioal array\n",
    "data = np.array(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "#Mendefinisikan obyek MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#Transformation data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print('Data Normalisasi')\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[[100.       0.0001]\n",
      " [ 50.       0.05  ]\n",
      " [ 30.       0.003 ]]\n",
      "Data Standarisasi\n",
      "[[ 1.358732 -0.76956 ]\n",
      " [-0.339683  1.412317]\n",
      " [-1.019049 -0.642757]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.set_printoptions(precision=6) #bulatkan 4 angka koma\n",
    "np.set_printoptions(suppress=True) #hilangkan nilai e\n",
    "\n",
    "# Kita akan membentuk data\n",
    "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
    "# dalam bentuk n-dimensional array\n",
    "data = [\n",
    "    [100, 0.0001],\n",
    "    [50, 0.05],\n",
    "    [30, 0.003]\n",
    "]\n",
    "\n",
    "#Ubah ke bentuk numpy n-dimensioal array\n",
    "data = np.asarray(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "#Mendefinisikan obyek MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "#Transformation data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print('Data Standarisasi')\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "Data Transformasi Ordinal Encoder\n",
      "[[2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#Inisiasi obyek ordinal Encoder\n",
    "oe = OrdinalEncoder()\n",
    "\n",
    "#Definisikan data\n",
    "#Dalam bentuk 2d\n",
    "data = [\n",
    "    ['Politeknik Negeri Malang'],\n",
    "    ['Politeknik Elektronika Negeri Surabaya'],\n",
    "    ['Politeknik Negeri Jakarta'],\n",
    "    ['Politeknik Negeri Semarang'],\n",
    "]\n",
    "\n",
    "#Transformasi Ordinal Encoder\n",
    "transform_oe = oe.fit_transform(data)\n",
    "\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "print('Data Transformasi Ordinal Encoder')\n",
    "print(transform_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "Data Transformasi One-Hot Encoding\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Inisiasi obyek Ordinal Encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "#Definisikan data\n",
    "#Dalam bentuk 2d\n",
    "\n",
    "data = [\n",
    "    ['Politeknik Negeri Malang'],\n",
    "    ['Politeknik Elektronika Negeri Surabaya'],\n",
    "    ['Politeknik Negeri Jakarta'],\n",
    "    ['Politeknik Negeri Semarang'],\n",
    "]\n",
    "\n",
    "#Tranformasi One Hot Encoder\n",
    "transform_ohe = ohe.fit_transform(data)\n",
    "\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "print('Data Transformasi One-Hot Encoding')\n",
    "print(transform_ohe.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "Data Transformasi One-Hot Encoding\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Inisiasi obyek Ordinal Encoder\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "\n",
    "#Definisikan data\n",
    "#Dalam bentuk 2d\n",
    "\n",
    "data = [\n",
    "    ['Politeknik Negeri Malang'],\n",
    "    ['Politeknik Elektronika Negeri Surabaya'],\n",
    "    ['Politeknik Negeri Jakarta'],\n",
    "    ['Politeknik Negeri Semarang'],\n",
    "]\n",
    "\n",
    "#Tranformasi One Hot Encoder\n",
    "transform_ohe = ohe.fit_transform(data)\n",
    "\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "print('Data Transformasi One-Hot Encoding')\n",
    "print(transform_ohe.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil TF-IDF\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n",
      "Hasil Token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ate', 'away', 'cat', 'end', 'finally', 'house', 'little', 'mouse',\n",
       "       'ran', 'saw', 'story', 'tiny'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse ran away from the house',\n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]\n",
    "\n",
    "#Inisiasi obyek TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "#Cetak hasil\n",
    "print('Hasil TF-IDF')\n",
    "print(resp)\n",
    "\n",
    "#Cetak kata yang dihasilkan\n",
    "print('Hasil Token')\n",
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil TF-IDF:\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (4, 10)\t0.6700917930430479\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 7)\t0.3193023297639811\n",
      "Hasil Token:\n",
      "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
      " 'story' 'tiny']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Baca konten dari file corpus.txt\n",
    "with open('corpus.txt', 'r') as file:\n",
    "    corpus = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Inisiasi obyek TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak hasil\n",
    "print('Hasil TF-IDF:')\n",
    "print(resp)\n",
    "\n",
    "# Cetak kata yang dihasilkan (token)\n",
    "print('Hasil Token:')\n",
    "print(vect.get_feature_names_out())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
