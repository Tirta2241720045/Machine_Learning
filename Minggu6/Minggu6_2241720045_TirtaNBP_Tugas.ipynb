{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Tirta2241720045/Machine_Learning/blob/main/Minggu6/Minggu6_2241720045_TirtaNBP_Tugas.ipynb",
      "authorship_tag": "ABX9TyNsQOHpX1Hu+xGf+SyN/M2n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tirta2241720045/Machine_Learning/blob/main/Minggu6/Minggu6_2241720045_TirtaNBP_Tugas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nama: Tirta Nurrochman Bintang Prawira\n",
        "# NIM: 2241720045\n",
        "# Kelas: TI-3A\n",
        "# No: 27\n",
        "#Tugas\n"
      ],
      "metadata": {
        "id": "hUhliDTLsHB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5PdQK8OgtQvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "FvXXGcfsvCfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tugas 1\n",
        "- Terdapat dataset mushroom. Berdasarkan dataset yang tersebut, bandingkan peforma antara algoritma Decision Tree dan RandomForest. Gunakan tunning hyperparameter untuk mendapatkan parameter dan akurasi yang terbaik."
      ],
      "metadata": {
        "id": "CdzX1Ph_tQFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library"
      ],
      "metadata": {
        "id": "dDrzZshltTj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "EcfofovBtdcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "- numpy dan pandas digunakan untuk memanipulasi dan mengolah data.\n",
        "- train_test_split digunakan untuk membagi dataset menjadi data latih dan data uji.\n",
        "- GridSearchCV digunakan untuk melakukan pencarian parameter terbaik untuk model dengan metode cross-validation.\n",
        "- DecisionTreeClassifier dan RandomForestClassifier adalah model yang akan digunakan.\n",
        "- accuracy_score dan classification_report digunakan untuk mengevaluasi kinerja model.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "RzFhLieht752"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persiapan Data"
      ],
      "metadata": {
        "id": "6PXehdD4tV2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "mushroom_data = pd.read_csv('/content/drive/MyDrive/dataset/mushrooms.csv')\n",
        "\n",
        "# Melihat 5 baris pertama dataset\n",
        "print(mushroom_data.head())\n",
        "\n",
        "# Mengganti label string menjadi numerik (jika diperlukan)\n",
        "mushroom_data['class'] = mushroom_data['class'].map({'e': 1, 'p': 0})  # e: edible, p: poisonous\n",
        "\n",
        "# Menggunakan One-Hot Encoding untuk fitur kategorikal\n",
        "mushroom_data = pd.get_dummies(mushroom_data, drop_first=True)\n",
        "\n",
        "# Memisahkan fitur dan label\n",
        "X = mushroom_data.drop('class', axis=1)\n",
        "y = mushroom_data['class']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGd4Xe2atfzo",
        "outputId": "b98a90fb-4fbc-4bb8-af15-a96cc211c679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
            "0     p         x           s         n       t    p               f   \n",
            "1     e         x           s         y       t    a               f   \n",
            "2     e         b           s         w       t    l               f   \n",
            "3     p         x           y         w       t    p               f   \n",
            "4     e         x           s         g       f    n               f   \n",
            "\n",
            "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
            "0            c         n          k  ...                        s   \n",
            "1            c         b          k  ...                        s   \n",
            "2            c         b          n  ...                        s   \n",
            "3            c         n          n  ...                        s   \n",
            "4            w         b          k  ...                        s   \n",
            "\n",
            "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
            "0                      w                      w         p          w   \n",
            "1                      w                      w         p          w   \n",
            "2                      w                      w         p          w   \n",
            "3                      w                      w         p          w   \n",
            "4                      w                      w         p          w   \n",
            "\n",
            "  ring-number ring-type spore-print-color population habitat  \n",
            "0           o         p                 k          s       u  \n",
            "1           o         p                 n          n       g  \n",
            "2           o         p                 n          n       m  \n",
            "3           o         p                 k          s       u  \n",
            "4           o         e                 n          a       g  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "- Dataset jamur dimuat ke dalam DataFrame menggunakan pd.read_csv.\n",
        "- head() digunakan untuk menampilkan lima baris pertama dari dataset agar kita bisa melihat strukturnya.\n",
        "- Label kolom 'class' yang berisi informasi apakah jamur dapat dimakan ('e') atau beracun ('p') diubah menjadi nilai numerik (1 untuk edible dan 0 untuk poisonous).\n",
        "- One-Hot Encoding digunakan untuk mengubah fitur kategorikal menjadi format numerik, yang diperlukan oleh algoritma pembelajaran mesin.\n",
        "- Fitur (X) dipisahkan dari label (y), di mana X adalah semua kolom kecuali 'class', dan y adalah kolom 'class'.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ZG7Lv3Z9uIQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data Training dan Testing"
      ],
      "metadata": {
        "id": "SlYUKJK1tXZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Tzv4tPPOtliX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "- Dataset dibagi menjadi data latih (70%) dan data uji (30%) menggunakan train_test_split.\n",
        "- random_state=42 digunakan untuk memastikan hasil pembagian dataset dapat direproduksi.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "eWuj3VhguS59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Decision Tree dengan Tuning Hyperparameter"
      ],
      "metadata": {
        "id": "eDFkMz_ttZMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan parameter untuk Grid Search\n",
        "param_grid_dt = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Menggunakan GridSearchCV untuk mencari parameter terbaik\n",
        "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=5)\n",
        "grid_search_dt.fit(X_train, y_train)\n",
        "\n",
        "# Mendapatkan model terbaik dan akurasi\n",
        "best_dt_model = grid_search_dt.best_estimator_\n",
        "y_pred_dt = best_dt_model.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "print(\"Best Decision Tree Parameters:\", grid_search_dt.best_params_)\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6mlBDeltotj",
        "outputId": "90a56e07-f538-46df-b4a6-855ed9f6c07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
            "Decision Tree Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "- Parameter yang akan diuji untuk Decision Tree didefinisikan dalam param_grid_dt, termasuk kriteria pembagian (criterion), kedalaman maksimum pohon (max_depth), dan jumlah minimum sampel untuk membagi node (min_samples_split).\n",
        "- GridSearchCV digunakan untuk mencari kombinasi parameter terbaik dari model Decision Tree. cv=5 menunjukkan bahwa cross-validation dilakukan dengan 5 lipatan.\n",
        "- Model terbaik dari hasil pencarian disimpan dalam best_dt_model, dan akurasinya dihitung dengan membandingkan prediksi pada data uji dengan label sebenarnya menggunakan accuracy_score.\n",
        "- Hasil parameter terbaik dan akurasi dicetak.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "lIDYq-RZuXfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Random Forest dengan Tuning Hyperparameter"
      ],
      "metadata": {
        "id": "7gLmPz-7taqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan parameter untuk Grid Search\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Menggunakan GridSearchCV untuk mencari parameter terbaik\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Mendapatkan model terbaik dan akurasi\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Best Random Forest Parameters:\", grid_search_rf.best_params_)\n",
        "print(\"Random Forest Accuracy:\", rf_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mODpWXo0tt6x",
        "outputId": "2ca6fd54-7a94-4828-82ed-e9ea4811957d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "- Parameter untuk model Random Forest didefinisikan dalam param_grid_rf, termasuk jumlah estimator (n_estimators), kriteria pembagian, kedalaman maksimum, dan jumlah minimum sampel untuk membagi node.\n",
        "- Seperti sebelumnya, GridSearchCV digunakan untuk mencari kombinasi parameter terbaik dengan cross-validation.\n",
        "- Model terbaik dan akurasinya diperoleh dengan cara yang sama seperti pada model Decision Tree, dan hasilnya dicetak.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rIDoETy1ueO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "### Kesimpulan\n",
        "Setelah melakukan pelatihan dan tuning hyperparameter, hasil yang diperoleh adalah:\n",
        "\n",
        "- **Decision Tree:**\n",
        "  - **Best Parameters:** `{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}`\n",
        "  - **Accuracy:** 1.0\n",
        "\n",
        "- **Random Forest:**\n",
        "  - **Best Parameters:** `{'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}`\n",
        "  - **Accuracy:** 1.0\n",
        "\n",
        "Kedua model mencapai akurasi sempurna (1.0), menunjukkan kemampuan mereka dalam mengklasifikasikan dataset jamur dengan sangat baik. Namun, Random Forest lebih robust terhadap overfitting dibandingkan Decision Tree, menjadikannya pilihan yang lebih baik untuk aplikasi di masa mendatang.\n",
        "\n",
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "odOwX6X9u4WC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tugas 2\n",
        "- Terdapat dataset mushroom. Berdasarkan dataset tersebut, bandingkan peforma antara algoritma Decision Tree dan AdaBoost. Gunakan tunning hyperparameter untuk mendapatkan parameter dan akurasi yang terbaik.\n",
        "\n"
      ],
      "metadata": {
        "id": "HgPm-zdmtKCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Library"
      ],
      "metadata": {
        "id": "o9DRrBARv-MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Sjjhpm-dwJ1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **`import pandas as pd`**: Untuk manipulasi data.\n",
        "2. **`import numpy as np`**: Untuk komputasi numerik.\n",
        "3. **`from sklearn.model_selection import train_test_split, GridSearchCV`**: Untuk membagi data dan pencarian hyperparameter.\n",
        "4. **`from sklearn.tree import DecisionTreeClassifier`**: Untuk klasifikasi dengan pohon keputusan.\n",
        "5. **`from sklearn.ensemble import AdaBoostClassifier`**: Untuk algoritma boosting.\n",
        "6. **`from sklearn.metrics import accuracy_score, classification_report`**: Untuk evaluasi model.\n",
        "7. **`from sklearn.preprocessing import LabelEncoder`**: Untuk mengonversi label kategori.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "BcYu6TPCyhGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persiapan Data"
      ],
      "metadata": {
        "id": "WCVip1UkwBiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset/mushrooms.csv')\n",
        "\n",
        "# Cek informasi dataset\n",
        "print(data.info())\n",
        "\n",
        "# Mengubah kolom 'class' menjadi numerik menggunakan LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data['class'] = le.fit_transform(data['class'])  # Mengubah kolom target 'class' menjadi numerik\n",
        "\n",
        "# Mengubah kolom kategorikal lainnya menjadi one-hot encoding\n",
        "data_encoded = pd.get_dummies(data.drop('class', axis=1), drop_first=True)\n",
        "\n",
        "# Pisahkan fitur dan target\n",
        "X = data_encoded\n",
        "y = data['class']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpvtpKF_wKxe",
        "outputId": "90dce752-ab44-4568-b823-4bda0eba2aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8124 entries, 0 to 8123\n",
            "Data columns (total 23 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   class                     8124 non-null   object\n",
            " 1   cap-shape                 8124 non-null   object\n",
            " 2   cap-surface               8124 non-null   object\n",
            " 3   cap-color                 8124 non-null   object\n",
            " 4   bruises                   8124 non-null   object\n",
            " 5   odor                      8124 non-null   object\n",
            " 6   gill-attachment           8124 non-null   object\n",
            " 7   gill-spacing              8124 non-null   object\n",
            " 8   gill-size                 8124 non-null   object\n",
            " 9   gill-color                8124 non-null   object\n",
            " 10  stalk-shape               8124 non-null   object\n",
            " 11  stalk-root                8124 non-null   object\n",
            " 12  stalk-surface-above-ring  8124 non-null   object\n",
            " 13  stalk-surface-below-ring  8124 non-null   object\n",
            " 14  stalk-color-above-ring    8124 non-null   object\n",
            " 15  stalk-color-below-ring    8124 non-null   object\n",
            " 16  veil-type                 8124 non-null   object\n",
            " 17  veil-color                8124 non-null   object\n",
            " 18  ring-number               8124 non-null   object\n",
            " 19  ring-type                 8124 non-null   object\n",
            " 20  spore-print-color         8124 non-null   object\n",
            " 21  population                8124 non-null   object\n",
            " 22  habitat                   8124 non-null   object\n",
            "dtypes: object(23)\n",
            "memory usage: 1.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Memuat Dataset**: Membaca dataset dari file CSV.\n",
        "\n",
        "2. **Cek Informasi Dataset**: Menampilkan informasi tentang DataFrame.\n",
        "\n",
        "3. **Mengubah Kolom 'Class' Menjadi Numerik**: Mengonversi kolom 'class' menjadi format numerik.\n",
        "\n",
        "4. **One-Hot Encoding**: Mengonversi kolom kategorikal lainnya menjadi one-hot encoding.\n",
        "\n",
        "5. **Pisahkan Fitur dan Target**: Memisahkan data menjadi fitur (`X`) dan target (`y`).\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "wfvc1G5Dyqzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data Training dan Testing"
      ],
      "metadata": {
        "id": "-oPguPwCwDhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi dataset menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ibvOQHyZwxvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "- **`train_test_split`**: Fungsi ini digunakan untuk membagi dataset.\n",
        "- **`X`**: Merupakan fitur yang telah diproses.\n",
        "- **`y`**: Merupakan target yang ingin diprediksi.\n",
        "- **`test_size=0.3`**: Menentukan bahwa 30% dari data akan digunakan sebagai data uji.\n",
        "- **`random_state=42`**: Menetapkan seed untuk pembagian data sehingga hasilnya dapat direproduksi.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "iSr0XgDUzGIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Decision Tree dengan Tuning Hyperparameter"
      ],
      "metadata": {
        "id": "q-FZIkzhwEyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning hyperparameter untuk Decision Tree\n",
        "dt_params = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None] + list(range(1, 11)),\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_grid_search = GridSearchCV(dt_classifier, dt_params, cv=5, scoring='accuracy')\n",
        "dt_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Menampilkan hasil terbaik\n",
        "print(\"Best Decision Tree Parameters:\", dt_grid_search.best_params_)\n",
        "dt_best = dt_grid_search.best_estimator_\n",
        "\n",
        "# Evaluasi akurasi\n",
        "dt_y_pred = dt_best.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
        "print(\"Decision Tree Accuracy:\", dt_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY8CEc-Bw0dq",
        "outputId": "8396b99f-51ee-4262-d192-384775fb3d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2}\n",
            "Decision Tree Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Tuning Hyperparameter**:\n",
        "   - **`dt_params`**: Parameter untuk tuning Decision Tree (metode pemisahan, kedalaman, dan minimal sampel untuk pembagian).\n",
        "  \n",
        "2. **Inisialisasi Model**:\n",
        "   - **`dt_classifier`**: Membuat model Decision Tree.\n",
        "\n",
        "3. **Grid Search**:\n",
        "   - **`dt_grid_search`**: Mencari parameter terbaik menggunakan `GridSearchCV` dengan akurasi sebagai metrik dan 5-fold cross-validation.\n",
        "\n",
        "4. **Pelatihan Model**:\n",
        "   - **`dt_grid_search.fit(X_train, y_train)`**: Melatih model dengan data latih.\n",
        "\n",
        "5. **Hasil Terbaik**:\n",
        "   - Menampilkan parameter terbaik yang ditemukan dan menyimpan model tersebut dalam **`dt_best`**.\n",
        "\n",
        "6. **Evaluasi Akurasi**:\n",
        "   - **`dt_y_pred`**: Prediksi kelas pada data uji.\n",
        "   - **`dt_accuracy`**: Menghitung dan menampilkan akurasi model.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "VF33kF44zkQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training AdaBoost dengan Tuning Hyperparameter"
      ],
      "metadata": {
        "id": "ldzxF856wF-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan parameter grid untuk tuning\n",
        "ab_params = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "}\n",
        "\n",
        "# Mengubah algoritma menjadi SAMME untuk menghindari FutureWarning dan gunakan estimator\n",
        "ab_classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(), algorithm='SAMME')\n",
        "\n",
        "# Menggunakan GridSearchCV untuk mencari parameter terbaik\n",
        "ab_grid_search = GridSearchCV(ab_classifier, ab_params, cv=5, scoring='accuracy')\n",
        "ab_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Menampilkan hasil terbaik\n",
        "print(f\"Best AdaBoost Parameters: {ab_grid_search.best_params_}\")\n",
        "print(f\"AdaBoost Accuracy: {ab_grid_search.best_score_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRHf3eDQw2y8",
        "outputId": "00da9976-16ee-48e0-d382-73f0843b6d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best AdaBoost Parameters: {'learning_rate': 0.01, 'n_estimators': 50}\n",
            "AdaBoost Accuracy: 0.9996481970096746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. Parameter Grid: Mengatur parameter yang akan diuji pada algoritma AdaBoost, seperti jumlah estimators dan learning rate.\n",
        "2. Inisialisasi AdaBoost: Membuat model AdaBoost dengan Decision Tree sebagai estimator dasar dan algoritma SAMME untuk menghindari peringatan.\n",
        "3. Grid Search: Mencari kombinasi parameter terbaik menggunakan GridSearchCV dengan 5-fold cross-validation.\n",
        "4. Pelatihan: Melatih model dengan data latih.\n",
        "5. Hasil Terbaik: Menampilkan parameter terbaik yang ditemukan dan akurasi model AdaBoost.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "sejVewMpzoje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "### Kesimpulan\n",
        "\n",
        "1. **Decision Tree**:\n",
        "   - **Parameter Terbaik**: `criterion` Gini, `max_depth` None, `min_samples_split` 2.\n",
        "   - **Akurasi**: 1.0 (sempurna).\n",
        "\n",
        "2. **AdaBoost**:\n",
        "   - **Parameter Terbaik**: `learning_rate` 0.01, `n_estimators` 50.\n",
        "   - **Akurasi**: 99.96%.\n",
        "\n",
        "Kedua model menunjukkan performa yang sangat baik, dengan Decision Tree mencapai akurasi sempurna.\n",
        "\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "G6N0tQTy0kA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tugas 3\n",
        "- Dengan menggunakan dataset diabetes, buatlah ensemble voting dengan algoritma\n",
        "1. Logistic Regression\n",
        "2. SVM kernel polynomial\n",
        "3. Decission Tree\n",
        "- Anda boleh melakukan eksplorasi dengan melakukan tunning hyperparameter"
      ],
      "metadata": {
        "id": "QHgvK_k5tLQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langkah 1: Import Library dan Memuat Dataset"
      ],
      "metadata": {
        "id": "D1dtvUNO1VdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Memuat dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/dataset/diabetes (1).csv')\n",
        "\n",
        "# Cek informasi dataset\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGkkioQo1U2P",
        "outputId": "610c2404-7b2b-4c80-8c8d-8f9fb5e6b648"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Impor Library**: Mengimpor pustaka yang diperlukan untuk pengolahan data dan machine learning.\n",
        "2. **Muat Dataset**: Membaca dataset diabetes dari file CSV.\n",
        "3. **Cek Informasi**: Menampilkan informasi tentang struktur dan tipe data dalam dataset.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "T9QAcQe_2j54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 2: Preprocessing Data"
      ],
      "metadata": {
        "id": "0OQv2IzJ1cpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan fitur dan target\n",
        "X = data.drop('Outcome', axis=1)  # Asumsikan kolom target bernama 'Outcome'\n",
        "y = data['Outcome']\n",
        "\n",
        "# Membagi dataset menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "slld8o691d2P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Pisahkan Fitur dan Target**:\n",
        "   - `X` berisi semua fitur (kolom) dari dataset kecuali kolom target (`Outcome`).\n",
        "   - `y` berisi kolom target (`Outcome`).\n",
        "\n",
        "2. **Bagi Dataset**:\n",
        "   - Menggunakan `train_test_split` untuk membagi dataset menjadi data latih (70%) dan data uji (30%).\n",
        "   - `random_state=42` memastikan pembagian yang konsisten setiap kali kode dijalankan.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "oAtrq-pd3HrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langkah 3: Definisikan dan Tuning Model\n",
        "1. Logistic Regression"
      ],
      "metadata": {
        "id": "T_Draiva1gSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Membangun pipeline untuk menyekal data dan melakukan Logistic Regression\n",
        "log_reg = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Mendefinisikan hyperparameter untuk GridSearch\n",
        "log_params = {\n",
        "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'logisticregression__solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "# Melakukan GridSearchCV\n",
        "log_grid_search = GridSearchCV(log_reg, log_params, cv=5, scoring='accuracy')\n",
        "log_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Menampilkan parameter terbaik\n",
        "print(\"Best Logistic Regression Parameters:\", log_grid_search.best_params_)\n",
        "\n",
        "# Mendapatkan model terbaik\n",
        "best_model = log_grid_search.best_estimator_\n",
        "\n",
        "# Melakukan prediksi pada data uji\n",
        "y_pred_log = best_model.predict(X_test)\n",
        "\n",
        "# Menghitung akurasi dengan accuracy_score\n",
        "acc_log = accuracy_score(y_test, y_pred_log)\n",
        "\n",
        "# Menampilkan hasil akurasi\n",
        "print(f\"Accuracy of Logistic Regression: {acc_log:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXfVHERI1nn8",
        "outputId": "be5d74e8-5454-43aa-80fe-40790461fe25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression Parameters: {'logisticregression__C': 0.1, 'logisticregression__solver': 'lbfgs'}\n",
            "Accuracy of Logistic Regression: 0.7403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Pemisahan Data**: Memisahkan fitur dan target dari dataset.\n",
        "2. **Pembagian Data**: Membagi data menjadi set latih (70%) dan set uji (30%).\n",
        "3. **Pipeline**: Membangun pipeline yang menyekal data menggunakan `StandardScaler` dan menerapkan `LogisticRegression`.\n",
        "4. **Grid Search**: Menggunakan `GridSearchCV` untuk mencari hyperparameter terbaik untuk model regresi logistik.\n",
        "5. **Output**: Menampilkan parameter terbaik yang ditemukan oleh Grid Search.\n",
        "--------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "8Umi9bod3RyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. SVM dengan Kernel Polynomial"
      ],
      "metadata": {
        "id": "mEZ1Cbf52KSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Tuning hyperparameter untuk SVM\n",
        "svm_params = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'degree': [2, 3, 4],\n",
        "    'kernel': ['poly']\n",
        "}\n",
        "\n",
        "svm = SVC()\n",
        "svm_grid_search = GridSearchCV(svm, svm_params, cv=5, scoring='accuracy')\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Menampilkan parameter terbaik\n",
        "print(\"Best SVM Parameters:\", svm_grid_search.best_params_)\n",
        "\n",
        "# Mendapatkan model terbaik\n",
        "best_svm_model = svm_grid_search.best_estimator_\n",
        "\n",
        "# Melakukan prediksi pada data uji\n",
        "y_pred_svm = best_svm_model.predict(X_test)\n",
        "\n",
        "# Menghitung akurasi dengan accuracy_score\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "# Menampilkan hasil akurasi\n",
        "print(f\"Accuracy of SVM: {acc_svm:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoaLiKaq2L8l",
        "outputId": "2c7d9d82-0cb0-43ca-80fa-fecf06dee939"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM Parameters: {'C': 10, 'degree': 2, 'kernel': 'poly'}\n",
            "Accuracy of SVM: 0.7403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Definisi Hyperparameter SVM**: Menentukan parameter yang dioptimalkan untuk model SVM, termasuk `C`, `degree`, dan `kernel`.\n",
        "2. **Inisialisasi Model**: Membuat objek SVM dengan `SVC()`.\n",
        "3. **Grid Search**: Menggunakan `GridSearchCV` untuk menemukan parameter terbaik dengan 5-fold cross-validation dan akurasi sebagai metrik.\n",
        "4. **Pelatihan Model**: Melatih model dengan `svm_grid_search.fit(X_train, y_train)`.\n",
        "5. **Output**: Menampilkan parameter terbaik dengan `print(\"Best SVM Parameters:\", svm_grid_search.best_params_)`.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Kq50oxOn4jnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Decision Tree"
      ],
      "metadata": {
        "id": "nJNXRpT-2SUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Tuning hyperparameter untuk Decision Tree\n",
        "dt_params = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None] + list(range(1, 11)),\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_grid_search = GridSearchCV(dt_classifier, dt_params, cv=5, scoring='accuracy')\n",
        "dt_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Menampilkan parameter terbaik\n",
        "print(\"Best Decision Tree Parameters:\", dt_grid_search.best_params_)\n",
        "\n",
        "# Mendapatkan model terbaik\n",
        "best_dt_model = dt_grid_search.best_estimator_\n",
        "\n",
        "# Melakukan prediksi pada data uji\n",
        "y_pred_dt = best_dt_model.predict(X_test)\n",
        "\n",
        "# Menghitung akurasi dengan accuracy_score\n",
        "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Menampilkan hasil akurasi\n",
        "print(f\"Accuracy of Decision Tree: {acc_dt:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0Tjdi0z2VAa",
        "outputId": "300b563f-2c18-42be-fefd-ce5f0ebdeacf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
            "Accuracy of Decision Tree: 0.7273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Definisi Hyperparameter Decision Tree**: Menentukan parameter yang dioptimalkan untuk model pohon keputusan, termasuk `criterion`, `max_depth`, dan `min_samples_split`.\n",
        "2. **Inisialisasi Model**: Membuat objek pohon keputusan dengan `DecisionTreeClassifier()`.\n",
        "3. **Grid Search**: Menggunakan `GridSearchCV` untuk menemukan parameter terbaik dengan 5-fold cross-validation dan akurasi sebagai metrik.\n",
        "4. **Pelatihan Model**: Melatih model dengan `dt_grid_search.fit(X_train, y_train)`.\n",
        "5. **Output**: Menampilkan parameter terbaik dengan `print(\"Best Decision Tree Parameters:\", dt_grid_search.best_params_)`.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "A2MTWcO84ui8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Membuat Ensemble Voting Classifier"
      ],
      "metadata": {
        "id": "CEQxDmkc2YY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan model terbaik dari grid search\n",
        "best_log_reg = log_grid_search.best_estimator_\n",
        "best_svm = svm_grid_search.best_estimator_\n",
        "best_dt = dt_grid_search.best_estimator_\n",
        "\n",
        "# Membuat ensemble voting classifier\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('log_reg', best_log_reg),\n",
        "    ('svm', best_svm),\n",
        "    ('decision_tree', best_dt)\n",
        "], voting='hard')\n",
        "\n",
        "# Melatih model ensemble\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluasi akurasi\n",
        "y_pred = voting_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Ensemble Voting Accuracy:\", accuracy)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl5wX5ZE2X-A",
        "outputId": "3e307344-6cd1-4ed9-c4e4-284a7eec4d4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Voting Accuracy: 0.7359307359307359\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80       151\n",
            "           1       0.62      0.60      0.61        80\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.71      0.70      0.71       231\n",
            "weighted avg       0.73      0.74      0.73       231\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "1. **Model Terbaik**: Mengambil model terbaik dari hasil grid search untuk regresi logistik, SVM, dan pohon keputusan.\n",
        "\n",
        "2. **Ensemble Voting Classifier**: Membuat model ensemble menggunakan `VotingClassifier` dengan voting 'hard', yang menggabungkan prediksi dari ketiga model terbaik.\n",
        "\n",
        "3. **Pelatihan Model Ensemble**: Melatih `voting_classifier` menggunakan data latih dengan `fit(X_train, y_train)`.\n",
        "\n",
        "4. **Prediksi dan Evaluasi**: Menghitung akurasi model ensemble pada data uji dengan `accuracy_score` dan menampilkan laporan klasifikasi dengan `classification_report`.\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "poKqyZMU45dT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------------------------------------------\n",
        "### Kesimpulan\n",
        "1. **Regresi Logistik**:\n",
        "   - **Parameter Terbaik**: `C = 0.1`, solver `lbfgs`.\n",
        "   - **Akurasi**: 74.03%. Model ini menunjukkan performa yang baik untuk masalah ini, namun masih ada ruang untuk perbaikan.\n",
        "\n",
        "2. **SVM (Kernel Polinomial)**:\n",
        "   - **Parameter Terbaik**: `C = 10`, derajat 2.\n",
        "   - **Akurasi**: 74.03%. SVM dengan kernel polinomial menunjukkan hasil yang setara dengan regresi logistik, tetapi lebih baik dalam menangani data non-linear.\n",
        "\n",
        "3. **Pohon Keputusan**:\n",
        "   - **Parameter Terbaik**: Kriteria `entropy`, kedalaman maksimum 4, min_samples_split 2.\n",
        "   - **Akurasi**: 72.73%. Model pohon keputusan menunjukkan performa yang sedikit lebih rendah dibandingkan dengan regresi logistik dan SVM, namun dapat dikontrol dengan pengaturan hyperparameter yang tepat.\n",
        "\n",
        "4. **Ensemble Voting Classifier**:\n",
        "   - **Akurasi**: 73.59%. Meskipun tidak jauh lebih tinggi dari model-model individual, penggunaan ensemble voting menunjukkan potensi untuk menggabungkan kekuatan berbagai model.\n",
        "   - **Performa Kelas**:\n",
        "     - **Precision** untuk kelas negatif (0): 79%, menunjukkan model lebih baik dalam memprediksi kelas negatif.\n",
        "     - **Precision** untuk kelas positif (1): 62%, menunjukkan model memiliki kesulitan dalam memprediksi kelas positif secara akurat, meskipun masih cukup baik dalam beberapa aspek.\n",
        "\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "J6BJ06os5GW6"
      }
    }
  ]
}